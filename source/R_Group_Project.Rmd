Skip to content
 TheMandarax / CSIT-165
Code Issues 0 Pull requests 1 Projects 0 Actions Wiki Security Pulse Community
CSIT-165/Project-1/template.Rmd
@TheMandarax TheMandarax Project 1
da4cf17 18 days ago
95 lines (70 sloc)  2.36 KB
 
---
title: "Project 1"
author: "Name:  \n Partner: "
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \usepackage{xcolor}
---
```{r setup, include = FALSE}
#### Load necessary packages ####
# * These packages are not necessary to complete the assignment and or only used 
#   to provide an example. 
packages <- c("knitr", "kableExtra", "magrittr", "readr", "geosphere")
install_me <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(install_me)) install.packages(install_me)
library(knitr)
#library(kableExtra)
library(magrittr)
library(readr)
library(geosphere)
```

## Background
The World Health Organization has recently employed a new data science initiative, *CSIT-165*, that uses data science to characterize pandemic diseases. 
*CSIT-165* disseminates data driven analyses to global decision makers.

*CSIT-165* is a conglomerate comprised of two fabricated entities: *Global Health Union (GHU)* and *Private Diagnostic Laboratories (PDL)*. 
Your and your partner's role is to play a data scientist from one of these two entities.

## Data
> [2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by John Hopkins CSSE](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series)
Data for 2019 Novel Coronavirus is operated by the John Hopkins University Center for Systems Science and Engineering (JHU CSSE).
Data includes daily time series CSV summary tables, including confirmations, recoveries, and deaths. 
Country/region are countries/regions hat conform to World Health Organization (WHO).
Lat and Long refer to coordinates references for the user. 
Date fields are stored in MM/DD/YYYY format.

## Project Objectives
######Make function definition file#############
######Make data grab happen in one place#######
### Objective 1
```{r ob1}
# Algorithm 
# Step1. Read in csv files.
# Step2. find which column is the first day.
# Step3. Make a list of the first days places as keys and with a count as the value
# Step4. go through the list and look for the max count, the corresponding location is the origin.
# Step5. Print the location.
add_first_day_cases <- function(lst, data_frame){
  for (i in 1:nrow(data_frame))
  {
    #key will be the name of the place without spaces added.
    key <- paste0(data_frame[ i, 1], " ", data_frame[ i, 2])
    
    num_of_cases <- data_frame[ i, 5]
    
    if (num_of_cases > 0 && is.null(lst[[key]]))
    {
      lst[[key]] <- num_of_cases
    }
    else if (num_of_cases > 0)
    {
      lst[[key]] <- lst[[key]] + num_of_cases
    }
    else
    {
      #do nothing
    }
  }
  lst # return lst
}

# read in data
confirmed <- read.csv(file="../data/time_series_covid19_confirmed_global.csv", stringsAsFactors = FALSE)

recovered <- read.csv(file="../data/time_series_covid19_recovered_global.csv", stringsAsFactors = FALSE)

deaths <- read.csv(file="../data/time_series_covid19_deaths_global.csv", stringsAsFactors = FALSE)

first_day_cases <- list()

# call function for each data set.
first_day_cases <- add_first_day_cases(first_day_cases, confirmed)

first_day_cases <- add_first_day_cases(first_day_cases, recovered)

first_day_cases <- add_first_day_cases(first_day_cases, deaths)

#Output answer
places <- names(first_day_cases)

ground_zero <- places[which.max(first_day_cases)]

print(paste0("Ground zero for the virus seems to be ", ground_zero, "."))


```
Objective 1, Answer: Now we believe this to be the origin because it has the maximum number of cases on day 0. See code comments for how the number of cases was computed. 

### Objective 2
```{r ob2}
confirmed <- read.csv(file="../data/time_series_covid19_confirmed_global.csv", stringsAsFactors = FALSE)
sums <- rowSums(confirmed[, 5:(ncol(confirmed)-1)])
current_day <- confirmed[, ncol(confirmed)]
new_cases <- vector()

for ( i in 1:length(sums))
{
  if (sums[i] == 0 && current_day[i] > 0)
    {
        new_cases <- c(new_cases, confirmed[i, 2])
    }
}

print(new_cases)
```

### Objective 3
```{r ob3}
confirmed <- read.csv(file="../data/time_series_covid19_confirmed_global.csv", stringsAsFactors = FALSE)
recent_places <- data.frame(Providence = nrow(confirmed), Country = ncol(confirmed), Lat = nrow(confirmed), Long = ncol(confirmed)) #Dataframe to contain lat and long
y <- 1
for(x in 1:nrow(confirmed)){ #iterates through rows
  i <- ncol(confirmed) #Start at the last column
  new_cases <- confirmed[x,i] #Values for the number of cases
  cases_before <- confirmed[x,(i-1)] #Values for the number of cases the day before
  if (new_cases > 0 && cases_before == 0){ #The first date of instance
    recent_places[y,1:4] <- confirmed[x,1:4]
    y <- y + 1
  } else {
  i <- i - 1 #Move back one column to find previous day if no matches found
  }
}
recent_places <- recent_places[1:(y-1),] #Truncate dataframe to correct size
y <- 1
first_place <- data.frame(Providence = 1, Country = 1, Lat = 1, Long = 1)
cases_number <- 0
for (x in 1:nrow(confirmed)) {
  i <- 5 #Start at first column of case number data
  cases <- confirmed[x,i] #Values for the number of cases
  if (cases > cases_number) #Largest number of cases on earliest day reported
    {
    first_place[1,1:4] <- confirmed[x,1:4] 
    cases_number <- confirmed[x,i]
    }
  else 
  {
    i <- i + 1 #Move to next day if no cases found
  }
}
dist_meter <- geosphere::distm(recent_places[,4:3], first_place[1,4:3], fun = distGeo) #Distance in meters from origin
dist_mile <- dist_meter/1609.344 #Distance in miles from origin
full_info <- data.frame(recent_places[,2], dist_mile[], first_place[,1:2]) #Dataframe with print information
ordered_info <- full_info[order(dist_mile),] #Order by distance from least to greatest
cat(paste0(ordered_info[,1], " is ", ordered_info[,2], " miles away from ", ordered_info[,3], ", ", ordered_info[,4], sep="\n"))

```

### Objective 4

#### Objective 4.1
```{r ob4.1}
library("dplyr")
#Algorithm
#Step1. Find the risk for each area
#Step2. Find the burden for each area
#Step3. Find global risk and confirmed

# read in data
confirmed <- read.csv(file="../data/time_series_covid19_confirmed_global.csv", stringsAsFactors = FALSE)

recovered <- read.csv(file="../data/time_series_covid19_recovered_global.csv", stringsAsFactors = FALSE)

deaths <- read.csv(file="../data/time_series_covid19_deaths_global.csv", stringsAsFactors = FALSE)


global_recoveries <- sum(recovered[, length(recovered)])

global_deaths <- sum(deaths[, length(deaths)])

global_risk <- global_deaths / global_recoveries

modified_confirmed <- left_join(recovered, confirmed, by = c("Province.State", "Country.Region"))
modified_deaths <- left_join(recovered, deaths, by = c("Province.State", "Country.Region"))

risk <- modified_deaths[, ncol(modified_deaths)] / recovered[ , ncol(recovered)]

burden <- modified_confirmed[, ncol(modified_confirmed)] * risk

recovered_with_scores <- mutate(
  recovered,
  risk_score = risk,
  burden_score = burden
)

mins <- filter(recovered_with_scores, risk_score == min(recovered_with_scores$risk_score, na.rm = TRUE))
 
maxs <- filter(recovered_with_scores, risk_score == max(recovered_with_scores$risk_score, na.rm = TRUE, inf.rm = TRUE))
 mins <- select(mins, Province.State, Country.Region, risk_score, burden_score)
 maxs <- select(maxs, Province.State, Country.Region, risk_score, burden_score)
 mins
 maxs
```

#### Objective 4.2
```{r ob4.2}
install.packages("dplyr")
library("dplyr")

#Generates total data frames
generate_total_df <- function(places, sums, column_name)
{
  countries <- vector()
  
  total_cases <- vector()
  
  for (i in 1:length(places)){
    
    if (is.element(places[i], countries)){
      
      new <- match(places[i], countries)
      
      total_cases[new] <- total_cases[new] + sums[i] 
      
    }
    else{
      
      countries <- c(countries, places[i])
      
      total_cases <- c(total_cases, sums[i])
      
    }
  }
  
  total_cases <- data.frame(countries, total_cases)
  
  colnames(total_cases) <- c("countries", column_name)
  
  total_cases
  
}

#Read input from csv files

confirmed <- read.csv(file="../data/time_series_covid19_confirmed_global.csv", stringsAsFactors = FALSE)

recovered <- read.csv(file="../data/time_series_covid19_recovered_global.csv", stringsAsFactors = FALSE)

deaths <- read.csv(file="../data/time_series_covid19_deaths_global.csv", stringsAsFactors = FALSE)

#calculate the sums of each

sums_confirmed <- confirmed[, ncol(confirmed)]

sums_recoveries <- recovered[, ncol(recovered)]

sums_deaths <- deaths[, ncol(deaths)]

#Generate the totals

total_confirmations <- generate_total_df(confirmed$Country.Region, sums_confirmed, "total_confirmations")

total_recoveries <- generate_total_df(recovered$Country.Region,  sums_recoveries, "total_recoveries")

total_deaths <- generate_total_df(deaths$Country.Region, sums_deaths, "total_deaths")

#Sort the data_frames
total_confirmations_sorted <- arrange(total_confirmations, -total_confirmations)

total_recoveries_sorted <-arrange(total_recoveries, -total_recoveries)

total_deaths_sorted <- arrange(total_deaths, -total_deaths)

#Output the data_frames as a table

kable(total_confirmations_sorted[1:5,])

kable(total_recoveries_sorted[1:5,])

kable(total_deaths_sorted[1:5,])

```

### GitHub Log
```{bash gitlog} 
git log --pretty=format:"%nSubject: %s%nAuthor: %aN%nDate: %aD%nBody: %b"
```





Â© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
